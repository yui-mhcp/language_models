{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "339c0250-b9bd-4c68-918d-ac8be9f60170",
   "metadata": {},
   "source": [
    "# Example workflow : document tagger\n",
    "\n",
    "This notebook proposes a comprehensive example of \"workflows\" or \"LLM agents\" created using the new `Node` API.\n",
    "This framework is inspired by multiple other frameworks, like `LangGraph`, `llama-index`, `agent development kit (ADK)`.\n",
    "The major distinction is that the proposed implementation is much simpler than the existing libraries, therefore proposing less features, but being much simpler to use, implement and extend.\n",
    "\n",
    "The provided use case is a document tagger : given a file (`docs`, `pdf` or any other format supported by `utils.text.parse_document`), and a list of tags with their descriptions, the workflow will attribute most relevant tags to the file.\n",
    "\n",
    "Such document tagging can be performed using multiple approaches depending on the size of the document and the capabilities of the underlying AI model.\n",
    "This notebook will explore multiple implementations with increasing level of complexity, to illustrate how to fully exploit the workflow framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c245ee95-5d02-486d-a34d-98151c51b2b5",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "The first step is to initialize model and define the tags with their criteria. In this example, I have defined a list of tags related to Large Language Models, and used the [MMaDA: Multimodal Large Diffusion Language Models](https://arxiv.org/abs/2505.15809) paper.\n",
    "This paper proposes a novel open-sourced 8B multimodal diffusion model, probably english-only as multilingual is not explicitel stated.\n",
    "The objective from the different workflow approaches will be to output the correct tags : `[llm, diffusion, multimodal, reasoning, open, small, mmlu, mmmu, math]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8349c595-145a-4a19-9356-09cdafe4e089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "\n",
    "from utils import *\n",
    "from utils.text import parse_document\n",
    "from models.nlu import TextGenerator\n",
    "from models.nlu.workflows import *\n",
    "\n",
    "filename = '../../mmada.pdf'\n",
    "\n",
    "tags = {\n",
    "    'llm' : 'if the paper presents a new large language model.',\n",
    "    'cnn' : 'if the paper proposes a new convolutional neural network.',\n",
    "    \n",
    "    'diffusion'  : 'if the paper proposes a new diffusion model',\n",
    "    'ar' : 'if the paper proposes an autoregressive architecture',\n",
    "\n",
    "    'reasoning'  : 'if the proposed model is a reasoning model (i.e., reasoning has been included during training)',\n",
    "    'multimodal' : 'if the paper proposes a new multimodal language model',\n",
    "    'multilingual' : 'if the proposed model is multilingual',\n",
    "\n",
    "    'open' : 'if the proposed model is open-source',\n",
    "    \n",
    "    'small': 'if the model is 15B parameters or smaller',\n",
    "    'medium' : 'if the model is between 15 and 40B parameters',\n",
    "    'big'    : 'if the model is bigger than 50B parameters',\n",
    "\n",
    "    'mmlu' : 'if the MMLU dataset has been used for evaluation',\n",
    "    'mmmu' : 'if the MMMU dataset has been used for evaluation',\n",
    "    'math' : 'if the MATH dataset has been used for evaluation',\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce6d9f7-d896-4fd0-ad3f-db63e1ea69f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'meta-llama/Meta-Llama-3.1-8B-Instruct'\n",
    "model_dir = model_name.split('/')[1].replace('-', '_') + '_int8_engine'\n",
    "path = os.path.expanduser('~/.cache/tensorrt_llm/{}/'.format(get_module_version('tensorrt_llm'))) + model_dir\n",
    "name = 'trtllm-{}_'.format(get_module_version('tensorrt_llm')) + model_dir.lower()\n",
    "\n",
    "model = TextGenerator(\n",
    "    lang = 'multi',\n",
    "    name = name,\n",
    "    tokenizer = model_name,\n",
    "    \n",
    "    path = path,\n",
    "    runtime = 'trt_llm',\n",
    "    kv_cache_free_gpu_memory = 2048, # this limits kv-cache memory to 2Gb\n",
    "    kv_cache_enable_block_reuse = True # this enables kv-cache reuse\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9ced23-3871-46e7-a7d2-395d227660c5",
   "metadata": {},
   "source": [
    "## Example 1 : naïve tagger implementation\n",
    "\n",
    "This first example asks the LLM to outputs the list of relevant tags based on the first page.\n",
    "The paper is 37 pages long, which is far too long for the model limited context window.\n",
    "Therefore, providing the first page (which contains the abstract) is a typical design choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdf9e0b-4ebf-4ade-a3ee-e080087665df",
   "metadata": {},
   "source": [
    "### Solution 1 : manual parsing and execution\n",
    "\n",
    "This first example simply parses the document, extracts the first page, and forwards it to the `model.infer` method.\n",
    "This illustrates a regular manual implementation of the naïve tagger.\n",
    "\n",
    "In this basic example, the model provides some of relevant tags, but fails on datasets and model size,\n",
    "as the information is not reported in the first page.\n",
    "Additionally, you have to parse the output with regular expressions to get the final list of tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8363ba2f-67ce-40a4-9b2b-45ad43097ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# paragraphs : 734 - # pages : 37\n",
      "# paragraphs in 1st page : 13\n"
     ]
    }
   ],
   "source": [
    "paragraphs = parse_document(filename)\n",
    "print('# paragraphs : {} - # pages : {}'.format(len(paragraphs), paragraphs[-1]['page'] + 1))\n",
    "\n",
    "first_page = [p for p in paragraphs if p['page'] == 0]\n",
    "print('# paragraphs in 1st page : {}'.format(len(first_page)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d2bc534-8854-429e-824c-97648d6c0ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRT-LLM] 25 tokens generated in 621 ms (40.216 tokens/sec)\n",
      "Input prompt :\n",
      "<|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 01 August 2025\n",
      "\n",
      "## Personality\n",
      "\n",
      "You are an AI assistant. You must respond as best as possible to user requests.\n",
      "\n",
      "## Information\n",
      "\n",
      "You have access to this information to help you respond. **Use it if it's relevant**!\n",
      "\n",
      "- File: ../../mmada.pdf\n",
      "- Page #0\n",
      "MMaDA: Multimodal Large Diffusion Language Models\n",
      "\n",
      "Ling Yang^1,^4∗†, Ye Tian^2∗, Bowen Li^2, Xinchen Zhang^3,\n",
      " Ke Shen^4, Yunhai Tong^2, Mengdi Wang^1\n",
      "^1 Princeton University ^2 Peking University ^3 Tsinghua University ^4 ByteDance Seed\n",
      "\n",
      "∗ Equal Contribution\n",
      "\n",
      "arXiv:2505.15809v1 [cs.CV] 21 May 2025\n",
      "\n",
      "Abstract\n",
      "\n",
      "We introduce  MMaDA, a novel class of multimodal diffusion foundation models designed to achieve\n",
      "superior performance across diverse domains such as textual reasoning, multimodal understanding,\n",
      " and text-to-image generation. The approach is distinguished by three key innovations: (i)  MMaDA\n",
      "adopts a unified diffusion architecture with a shared probabilistic formulation and a modality\u0002\n",
      "agnostic design, eliminating the need for modality-specific components. This architecture ensures\n",
      " seamless integration and processing across different data types. (ii)  We implement a  mixed long\n",
      " chain-of-thought (CoT) fine-tuning  strategy that curates a unified CoT format across modalities.\n",
      "By aligning reasoning processes between textual and visual domains, this strategy facilitates cold\u0002\n",
      "start training for the final reinforcement learning (RL) stage, thereby enhancing the model’s ability\n",
      " to handle complex tasks from the outset. (iii)  We propose  UniGRPO, a unified policy-gradient\u0002\n",
      "based RL algorithm specifically tailored for diffusion foundation models. Utilizing diversified\n",
      " reward modeling,  UniGRPO  unifies post-training across both reasoning and generation tasks,\n",
      " ensuring consistent performance improvements. Experimental results demonstrate that  MMaDA-8B\n",
      "exhibits strong generalization capabilities as a unified multimodal foundation model. It surpasses\n",
      "powerful models like LLaMA-3-7B and Qwen2-7B in textual reasoning, outperforms Show-o\n",
      "and SEED-X in multimodal understanding, and excels over SDXL and Janus in text-to-image\n",
      " generation. These achievements highlight  MMaDA ’s effectiveness in bridging the gap between\n",
      "pretraining and post-training within unified diffusion architectures, providing a comprehensive\n",
      "framework for future research and development. We open-source our code and trained models at:\n",
      "https://github.com/Gen-Verse/MMaDA\n",
      "\n",
      "^Date:  May 22, 2025\n",
      " Correspondence:  Ling Yang at  yangling0818@163.com\n",
      "\n",
      "1  Introduction\n",
      "\n",
      "Large language models (LLMs) have revolutionized natural language processing (NLP) by achieving state-of\u0002\n",
      " the-art performance in diverse tasks, from text generation (e.g., ChatGPT [ 1– 3]) to complex reasoning (e.g.,\n",
      " DeepSeek-R1 [ 4]). Inspired by their success, the research community has extended LLMs to the multimodal\n",
      " domain, giving rise to multimodal large language models (MLLMs) or vision-language models (VLMs) [ 5 14],\n",
      "\n",
      "such as GPT-4 [ 15] and Gemini [ 12]. These models aim to provide a unified framework for both understanding\n",
      "and generating across heterogeneous modalities—text, images, and beyond.\n",
      "\n",
      "Early multimodal approaches combined language models with diffusion models [ 16 19] to handle discrete (e.g.,\n",
      "\n",
      "text) and continuous (e.g., image) modalities separately. Subsequent autoregressive (AR) methods simplified\n",
      "\n",
      "1<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Output the relevant list of tags for the provided paper page(s).\n",
      "\n",
      "Here is the list of tags with their criteria : {\n",
      "    \"llm\": \"if the paper presents a new large language model.\",\n",
      "    \"cnn\": \"if the paper proposes a new convolutional neural network.\",\n",
      "    \"diffusion\": \"if the paper proposes a new diffusion model\",\n",
      "    \"ar\": \"if the paper proposes an autoregressive architecture\",\n",
      "    \"reasoning\": \"if the proposed model is a reasoning model (i.e., reasoning has been included during training)\",\n",
      "    \"multimodal\": \"if the paper proposes a new multimodal language model\",\n",
      "    \"multilingual\": \"if the proposed model is multilingual\",\n",
      "    \"open\": \"if the proposed model is open-source\",\n",
      "    \"small\": \"if the model is 15B parameters or smaller\",\n",
      "    \"medium\": \"if the model is between 15 and 40B parameters\",\n",
      "    \"big\": \"if the model is bigger than 50B parameters\",\n",
      "    \"mmlu\": \"if the MMLU dataset has been used for evaluation\",\n",
      "    \"mmmu\": \"if the MMMU dataset has been used for evaluation\",\n",
      "    \"math\": \"if the MATH dataset has been used for evaluation\"\n",
      "}\n",
      "\n",
      "You have to output a valid python list : `[\"tag 1\", \"tag 2\", ...]`<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "The relevant tags are : `[\n",
      "\n",
      "==================================================\n",
      "Output :\n",
      "The relevant tags are : `[ \"llm\", \"diffusion\", \"multimodal\", \"reasoning\", \"open\", \"big\" ]`\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Output the relevant list of tags for the provided paper page(s).\n",
    "\n",
    "Here is the list of tags with their criteria : {json.dumps(tags, indent = 4)}\n",
    "\n",
    "You have to output a valid python list : `[\"tag 1\", \"tag 2\", ...]`\n",
    "\"\"\"\n",
    "\n",
    "output = model.infer(\n",
    "    prompt,\n",
    "    lang = 'en',\n",
    "    paragraphs = first_page,\n",
    "    answer_start = \"The relevant tags are : `[\",\n",
    "    stop_condition = lambda text: text.rstrip().endswith('`'),\n",
    "    messages = []\n",
    ")\n",
    "\n",
    "print('Input prompt :\\n{}\\n\\n{}\\nOutput :\\n{}'.format(\n",
    "    output['prompt'], '=' * 50, output['predicted']\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6877ddb-12e6-45cc-adca-8ca2e9e4fe72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags : ['llm', 'diffusion', 'multimodal', 'reasoning', 'open', 'big']\n"
     ]
    }
   ],
   "source": [
    "tags_list = re.findall('\"(.*?)\"', output['predicted'])\n",
    "print('Tags : {}'.format(tags_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784b6f47-9202-4ab7-98a9-db19b1115051",
   "metadata": {},
   "source": [
    "### Solution 2 : workflow-based implementation\n",
    "\n",
    "This example reproduces the previous manual implementation by using workflows to automate file parsing and tags extraction to python list.\n",
    "The output is identical to the previous example, except that it is a regular python list containing the tags, making it easier to manipulate !\n",
    "\n",
    "Workflow explanation :\n",
    "- The `Graph` is an alias for `SequentialExecution`. It basically executes a list of nodes one after the other.\n",
    "- The `DocumentNode` calls `parse_document` on its input file.\n",
    "    - The `source_key` represents the key in the context for the filename input.\n",
    "    - The `output_key` is the context key where the output will be stored.\n",
    "    - This is quivalent to `context['output_key'] = parse_document(context['source_key'])`\n",
    "- The `FunctionNode` simply executes a function, taking the `context` as argument.\n",
    "- The `LLMNode` executes the `model.infer` method based on the given arguments.\n",
    "    - The `source_key` represents the input text (the prompt).\n",
    "    - The `mapping` maps context keys to kwarg name. In this case, the \"first_page\" argument will be forwarded as \"paragraphs\" kwarg.\n",
    "    - The `keep_history` tells whether or not the model uses conversation history.\n",
    "- The `TextExtractorNode` parses the input text with regular expression. In this case, it extracts all texts between quotes and put them in a list.\n",
    "\n",
    "The core feature of this framework is that the `Graph` object is an instance of `Node` like any other `Node` in the graph.\n",
    "This means that you can execute manually each node, as shown in the below examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a4ec0be-6050-4e2a-9419-ab8f4b9034e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LLM] Time-to-first token : 19 ms\n",
      "[LLM] 25 tokens generated in 271 ms (91.926 tokens/sec)\n",
      "['llm', 'diffusion', 'multimodal', 'reasoning', 'open', 'big']\n"
     ]
    }
   ],
   "source": [
    "tagger = Graph(\n",
    "    DocumentNode(source_key = 'filename', output_key = 'paragraphs'),\n",
    "    FunctionNode(\n",
    "        lambda context: [para for para in context['paragraphs'] if para['page'] == 0],\n",
    "        output_key = 'first_page'\n",
    "    ),\n",
    "    LLMNode(\n",
    "        model = model,\n",
    "        lang  = 'en',\n",
    "        answer_start = \"The relevant tags are : `[\",\n",
    "        stop_condition = lambda text: text.rstrip().endswith('`'),\n",
    "        keep_history   = False,\n",
    "        \n",
    "        mapping    = {'first_page' : 'paragraphs'},\n",
    "        source_key = 'prompt',\n",
    "        output_key = 'llm_tags'\n",
    "    ),\n",
    "    TextExtractorNode(\n",
    "        pattern = '\"(.*?)\"', source_key = 'llm_tags', output_key = 'result'\n",
    "    )\n",
    ")\n",
    "\n",
    "ctx, result = tagger.start({'filename' : filename, 'prompt' : prompt})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f468d61a-d4ba-415b-a678-6ae3f80eb3b6",
   "metadata": {},
   "source": [
    "#### Sub-graph execution\n",
    "\n",
    "This example executes the `LLMNode` followed by the `TextExtractorNode` as functions by manually providing the context.\n",
    "This allows to check the correct behavior of each individual part of the workflow.\n",
    "\n",
    "The `context` is updated in-place, meaning that it can be forwarded to each successive call !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7eb4bbc-fb38-42a4-9c13-1169c5c17a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LLM] Time-to-first token : 19 ms\n",
      "[LLM] 25 tokens generated in 273 ms (91.504 tokens/sec)\n",
      "Output of LLMNode : The relevant tags are : `[ \"llm\", \"diffusion\", \"multimodal\", \"reasoning\", \"open\", \"big\" ]`\n",
      "- Context keys : ('prompt', 'first_page', 'llm_tags')\n",
      "Final output (type <class 'list'>) : ['llm', 'diffusion', 'multimodal', 'reasoning', 'open', 'big']\n",
      "- Context keys : ('prompt', 'first_page', 'llm_tags', 'result')\n"
     ]
    }
   ],
   "source": [
    "ctx = {'prompt' : prompt, 'first_page' : first_page}\n",
    "\n",
    "llm_tags = tagger.nodes[2](ctx)\n",
    "print('Output of LLMNode : {}\\n- Context keys : {}'.format(llm_tags, tuple(ctx.keys())))\n",
    "\n",
    "result = tagger.nodes[-1](ctx)\n",
    "print('Final output (type {}) : {}\\n- Context keys : {}'.format(type(result), result, tuple(ctx.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1372183-2b0e-4317-a1fc-b2030fab807d",
   "metadata": {},
   "source": [
    "#### Workflow plot\n",
    "\n",
    "The base `Node` class implements the `plot` method. Each node can override the `plot_node` to define a custom plotting strategy,\n",
    "like `Graph` that plots each sub-nodes as a sequence.\n",
    "As shown in the plot, this workflow is purely sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8e07d4a-f0b4-4a42-8be4-c448d36aa2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: SequentialExecution&#45;6 Pages: 1 -->\n",
       "<svg width=\"688pt\" height=\"443pt\"\n",
       " viewBox=\"0.00 0.00 688.00 443.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 439)\">\n",
       "<title>SequentialExecution&#45;6</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-439 684,-439 684,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_SequentialExecution&#45;6</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"8,-8 8,-427 672,-427 672,-8 8,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"340\" y=\"-411.8\" font-family=\"Times,serif\" font-size=\"14.00\">SequentialExecution&#45;6</text>\n",
       "</g>\n",
       "<!-- 0 -->\n",
       "<g id=\"0\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"513.5,-396 166.5,-396 166.5,-328 513.5,-328 513.5,-396\"/>\n",
       "<text text-anchor=\"middle\" x=\"340\" y=\"-380.8\" font-family=\"Times,serif\" font-size=\"14.00\">== Document ==</text>\n",
       "<text text-anchor=\"middle\" x=\"340\" y=\"-365.8\" font-family=\"Times,serif\" font-size=\"14.00\">&#45; Output key : paragraphs</text>\n",
       "<text text-anchor=\"middle\" x=\"340\" y=\"-350.8\" font-family=\"Times,serif\" font-size=\"14.00\">&#45; Input key : filename</text>\n",
       "<text text-anchor=\"middle\" x=\"340\" y=\"-335.8\" font-family=\"Times,serif\" font-size=\"14.00\">&#45; Function : utils.text.parsers.parse_document</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"1\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"663.5,-292 16.5,-292 16.5,-239 663.5,-239 663.5,-292\"/>\n",
       "<text text-anchor=\"middle\" x=\"340\" y=\"-276.8\" font-family=\"Times,serif\" font-size=\"14.00\">== Function ==</text>\n",
       "<text text-anchor=\"middle\" x=\"340\" y=\"-261.8\" font-family=\"Times,serif\" font-size=\"14.00\">&#45; Output key : first_page</text>\n",
       "<text text-anchor=\"middle\" x=\"340\" y=\"-246.8\" font-family=\"Times,serif\" font-size=\"14.00\">&#45; Function : lambda context: [para for para in context[&#39;paragraphs&#39;] if para[&#39;page&#39;] == 0]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M340,-327.95C340,-319.72 340,-310.85 340,-302.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"343.5,-302.24 340,-292.24 336.5,-302.24 343.5,-302.24\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"2\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"577,-203 103,-203 103,-120 577,-120 577,-203\"/>\n",
       "<text text-anchor=\"middle\" x=\"340\" y=\"-187.8\" font-family=\"Times,serif\" font-size=\"14.00\">== LLM ==</text>\n",
       "<text text-anchor=\"middle\" x=\"340\" y=\"-172.8\" font-family=\"Times,serif\" font-size=\"14.00\">&#45; Output key : llm_tags</text>\n",
       "<text text-anchor=\"middle\" x=\"340\" y=\"-157.8\" font-family=\"Times,serif\" font-size=\"14.00\">&#45; Input key : prompt</text>\n",
       "<text text-anchor=\"middle\" x=\"340\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\">&#45; Model &#160;: trtllm&#45;0.20.0_meta_llama_3.1_8b_instruct_int8_engine</text>\n",
       "<text text-anchor=\"middle\" x=\"340\" y=\"-127.8\" font-family=\"Times,serif\" font-size=\"14.00\">&#45; Method : answer</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M340,-238.76C340,-231.04 340,-222.29 340,-213.53\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"343.5,-213.32 340,-203.32 336.5,-213.32 343.5,-213.32\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"3\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"426.5,-84 253.5,-84 253.5,-16 426.5,-16 426.5,-84\"/>\n",
       "<text text-anchor=\"middle\" x=\"340\" y=\"-68.8\" font-family=\"Times,serif\" font-size=\"14.00\">== TextExtractor ==</text>\n",
       "<text text-anchor=\"middle\" x=\"340\" y=\"-53.8\" font-family=\"Times,serif\" font-size=\"14.00\">&#45; Output key : result</text>\n",
       "<text text-anchor=\"middle\" x=\"340\" y=\"-38.8\" font-family=\"Times,serif\" font-size=\"14.00\">&#45; Input key : llm_tags</text>\n",
       "<text text-anchor=\"middle\" x=\"340\" y=\"-23.8\" font-family=\"Times,serif\" font-size=\"14.00\">&#45; Pattern : &quot;(.*?)&quot;</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M340,-119.73C340,-111.52 340,-102.86 340,-94.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"343.5,-94.3 340,-84.3 336.5,-94.3 343.5,-94.3\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fa209a57890>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaa14bf-badd-43e1-8ea7-8dd0afba56c9",
   "metadata": {},
   "source": [
    "## Example 2 : multi-pages tagging\n",
    "\n",
    "In this second example, the LLM will be executed on each page separately, and all the selected tags will then be combined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ca49f7-689b-4270-858c-082777d65413",
   "metadata": {},
   "source": [
    "### Solution 1 : manual parsing and execution\n",
    "\n",
    "This first example simply parses the document, extracts the first page, and forwards it to the `model.infer` method.\n",
    "This illustrates a regular manual implementation of the naïve tagger.\n",
    "\n",
    "For simplicity, only the 18 first pages will be processed, as the remaining ones are references and appendixes with examples.\n",
    "\n",
    "In this second example, the model provides some of relevant tags, including some of the datasets.\n",
    "However, sequentially processing all the pages is relatively slow and may be optimized though parallelization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d773d604-9eb9-42ce-a96c-b360683ca49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# paragraphs : 734 - # pages : 37\n",
      "# paragraphs in pages 1 and 2 : 43\n"
     ]
    }
   ],
   "source": [
    "def group_paragraphs(paragraphs, nb_pages = 2):\n",
    "    \"\"\"\n",
    "        Group paragraphs into block of pages.\n",
    "        `output[i]` is the list of paragraphs ofr page indexes `range(i, i + nb_pages)`\n",
    "    \"\"\"\n",
    "    pages = {}\n",
    "    for para in paragraphs:\n",
    "        pages.setdefault(para['page'], []).append(para)\n",
    "\n",
    "    groups = []\n",
    "    for i, (page, content) in enumerate(sorted(pages.items())):\n",
    "        if i % nb_pages == 0:\n",
    "            groups.append(content)\n",
    "        else:\n",
    "            groups[-1].extend(content)\n",
    "    \n",
    "    return groups\n",
    "\n",
    "paragraphs = parse_document(filename)\n",
    "print('# paragraphs : {} - # pages : {}'.format(len(paragraphs), paragraphs[-1]['page'] + 1))\n",
    "\n",
    "pages = group_paragraphs(paragraphs, 2)\n",
    "print('# paragraphs in pages 1 and 2 : {}'.format(len(pages[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aadb01ff-063e-411b-80be-0f2636e62e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRT-LLM] 30 tokens generated in 608 ms (49.330 tokens/sec)\n",
      "Tags for group #0 : ['llm', 'diffusion', 'multimodal', 'reasoning', 'multimodal', 'open', 'medium']\n",
      "[TRT-LLM] 18 tokens generated in 544 ms (33.083 tokens/sec)\n",
      "Tags for group #1 : ['multimodal', 'reasoning', 'diffusion', 'ar']\n",
      "[TRT-LLM] 18 tokens generated in 588 ms (30.611 tokens/sec)\n",
      "Tags for group #2 : ['reasoning', 'multimodal', 'diffusion', 'ar']\n",
      "[TRT-LLM] 18 tokens generated in 553 ms (32.543 tokens/sec)\n",
      "Tags for group #3 : ['reasoning', 'multimodal', 'diffusion', 'ar']\n",
      "[TRT-LLM] 29 tokens generated in 788 ms (36.789 tokens/sec)\n",
      "Tags for group #4 : ['llm', 'multimodal', 'reasoning', 'multimodal', 'mmlu', 'mmmu']\n",
      "[TRT-LLM] 21 tokens generated in 500 ms (41.939 tokens/sec)\n",
      "Tags for group #5 : ['diffusion', 'multimodal', 'reasoning', 'open', 'medium']\n",
      "[TRT-LLM] 10 tokens generated in 494 ms (20.231 tokens/sec)\n",
      "Tags for group #6 : ['reasoning', 'diffusion']\n",
      "[TRT-LLM] 20 tokens generated in 548 ms (36.470 tokens/sec)\n",
      "Tags for group #7 : ['diffusion', 'multimodal', 'reasoning', 'mmlu']\n",
      "[TRT-LLM] 18 tokens generated in 700 ms (25.695 tokens/sec)\n",
      "Tags for group #8 : ['diffusion', 'multimodal', 'reasoning', 'big']\n",
      "All tags selected (time 5.465 sec) : {'medium', 'diffusion', 'big', 'multimodal', 'reasoning', 'open', 'ar', 'llm', 'mmlu', 'mmmu'}\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Output the relevant list of tags for the provided paper page(s).\n",
    "\n",
    "Here is the list of tags with their criteria : {json.dumps(tags, indent = 4)}\n",
    "\n",
    "You have to output a valid python list : `[\"tag 1\", \"tag 2\", ...]`\n",
    "\"\"\"\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "selected_tags = set()\n",
    "for i, pages_content in enumerate(pages[:9]):\n",
    "    output = model.infer(\n",
    "        prompt,\n",
    "        lang = 'en',\n",
    "        paragraphs = pages_content,\n",
    "        answer_start = \"The relevant tags are : `[\",\n",
    "        stop_condition = lambda text: text.rstrip().endswith('`'),\n",
    "        messages = []\n",
    "    )\n",
    "    tags_list = re.findall('\"(.*?)\"', output['predicted'])\n",
    "    print('Tags for group #{} : {}'.format(i, tags_list))   \n",
    "    selected_tags.update(tags_list)\n",
    "\n",
    "print('All tags selected (time {}) : {}'.format(time_to_string(time.time() - t0), selected_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404cfa92-0407-4112-a92b-281dbc01c40b",
   "metadata": {},
   "source": [
    "### Solution 2 : workflow based implementation\n",
    "\n",
    "This implementation reproduces the manual one while integrating parallelization to process multiple pages in parallel.\n",
    "Note that the arguments used during model initialization/engine construction limit the kv-cache memory available, and thus the number of\n",
    "inference it can perform in parallel. It is the reason why some generations start after others are finished. \n",
    "Nonetheless, the total time to process the 18 pages is less than 3 sec, compared to the 5.46 sec from the previous sequential execution !\n",
    "\n",
    "Workflow explanation :\n",
    "- The `DocumentNode` is equivalent to the naive example.\n",
    "- The `FunctionNode` uses the `source_key` argument to get the effective paragraphs as first argument instead of the context.\n",
    "- The `IteratorNode` is an abstraction, declined in `SequentialIteratorNode ` or `ParallelIteratorNode`. Passing `parallel = True` is equivalent to using the `ParallelIteratorNode` class directly.\n",
    "    - The `body` is the function (or node) executed on each item from the iterable\n",
    "    - The `iterable` is either the context key to use as iterable (like in this case) either an iterable (like a regular list)\n",
    "    - The `item_key` is the context key in which the current item will be stored. In the case of parallel execution, each call to `body` will have a copy of the context.\n",
    "    - The output from the `ParallelIteratorNode` is the list of individual result (i.e., `[body(item) for item in iterable]`)\n",
    "- The final `FunctionNode` simply combines all tags from each page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ee0dd41-c6a8-4dbf-a946-218fa54a9729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LLM] Time-to-first token : 185 ms\n",
      "[LLM] Time-to-first token : 664 ms\n",
      "[LLM] Time-to-first token : 677 ms\n",
      "[LLM] 18 tokens generated in 877 ms (20.513 tokens/sec)\n",
      "[LLM] Time-to-first token : 1.037 sec\n",
      "[LLM] 21 tokens generated in 1.097 sec (19.147 tokens/sec)\n",
      "[LLM] 20 tokens generated in 1.067 sec (18.746 tokens/sec)\n",
      "[LLM] Time-to-first token : 1.446 sec\n",
      "[LLM] Time-to-first token : 1.434 sec\n",
      "[LLM] 10 tokens generated in 1.559 sec (6.415 tokens/sec)\n",
      "[LLM] Time-to-first token : 1.780 sec\n",
      "[LLM] 18 tokens generated in 1.878 sec (9.586 tokens/sec)\n",
      "[LLM] Time-to-first token : 2.073 sec\n",
      "[LLM] 18 tokens generated in 2.114 sec (8.513 tokens/sec)\n",
      "[LLM] Time-to-first token : 2.361 sec\n",
      "[LLM] 18 tokens generated in 2.555 sec (7.045 tokens/sec)\n",
      "[LLM] 30 tokens generated in 2.635 sec (11.385 tokens/sec)\n",
      "[LLM] 29 tokens generated in 2.683 sec (10.808 tokens/sec)\n",
      "All tags selected (time 2.951 sec) : {'medium', 'diffusion', 'big', 'multimodal', 'reasoning', 'open', 'ar', 'llm', 'mmlu', 'mmmu'}\n"
     ]
    }
   ],
   "source": [
    "def group_paragraphs(paragraphs, nb_pages = 2, n_groups = 9):\n",
    "    \"\"\"\n",
    "        Group paragraphs into block of pages.\n",
    "        `output[i]` is the list of paragraphs ofr page indexes `range(i, i + nb_pages)`\n",
    "    \"\"\"\n",
    "    pages = {}\n",
    "    for para in paragraphs:\n",
    "        pages.setdefault(para['page'], []).append(para)\n",
    "\n",
    "    groups = []\n",
    "    for i, (page, content) in enumerate(sorted(pages.items())):\n",
    "        if i % nb_pages == 0:\n",
    "            groups.append(content)\n",
    "        else:\n",
    "            groups[-1].extend(content)\n",
    "    \n",
    "    return groups[:n_groups]\n",
    "\n",
    "def combine_tags(tags_list):\n",
    "    union = set()\n",
    "    for tags in tags_list: union.update(tags)\n",
    "    return union\n",
    "\n",
    "tagger = Graph(\n",
    "    DocumentNode(source_key = 'filename', output_key = 'paragraphs'),\n",
    "    FunctionNode(group_paragraphs, nb_pages = 2, source_key = 'paragraphs', output_key = 'pages'),\n",
    "    IteratorNode(\n",
    "        parallel = True,\n",
    "        \n",
    "        body = Graph(\n",
    "            LLMNode(\n",
    "                model = model,\n",
    "                lang  = 'en',\n",
    "                answer_start = \"The relevant tags are : `[\",\n",
    "                stop_condition = lambda text: text.rstrip().endswith('`'),\n",
    "                keep_history   = False,\n",
    "                \n",
    "                mapping    = {'page_content' : 'paragraphs'},\n",
    "                source_key = 'prompt',\n",
    "                output_key = 'llm_tags'\n",
    "            ),\n",
    "            TextExtractorNode(\n",
    "                pattern = '\"(.*?)\"', source_key = 'llm_tags'\n",
    "            )\n",
    "        ),\n",
    "        iterable = 'pages',\n",
    "        item_key = 'page_content',\n",
    "        output_key = 'tags_list'\n",
    "    ),\n",
    "    FunctionNode(combine_tags, source_key = 'tags_list', output_key = 'result')\n",
    ")\n",
    "\n",
    "t0 = time.time()\n",
    "ctx, result = tagger.start(filename = filename, prompt = prompt)\n",
    "\n",
    "print('All tags selected (time {}) : {}'.format(time_to_string(time.time() - t0), result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a10e759-9d9d-46a1-a33b-cb4efff82447",
   "metadata": {},
   "source": [
    "#### Workflow plot\n",
    "\n",
    "This new workflow has a much funnier plot ! It well represents the parallel execution of item generation and call to `body`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2298f004-488d-4fa5-bc19-2d409076e8d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: SequentialExecution&#45;5 Pages: 1 -->\n",
       "<svg width=\"530pt\" height=\"897pt\"\n",
       " viewBox=\"0.00 0.00 530.00 897.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 893)\">\n",
       "<title>SequentialExecution&#45;5</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-893 526,-893 526,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_SequentialExecution&#45;5</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"8,-8 8,-881 514,-881 514,-8 8,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"261\" y=\"-865.8\" font-family=\"Times,serif\" font-size=\"14.00\">SequentialExecution&#45;5</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>cluster_SequentialExecution&#45;4</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"16,-112 16,-323 506,-323 506,-112 16,-112\"/>\n",
       "<text text-anchor=\"middle\" x=\"261\" y=\"-307.8\" font-family=\"Times,serif\" font-size=\"14.00\">SequentialExecution&#45;4</text>\n",
       "</g>\n",
       "<!-- 0 -->\n",
       "<g id=\"0\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"434.5,-850 87.5,-850 87.5,-782 434.5,-782 434.5,-850\"/>\n",
       "<text text-anchor=\"middle\" x=\"261\" y=\"-834.8\" font-family=\"Times,serif\" font-size=\"14.00\">== Document ==</text>\n",
       "<text text-anchor=\"middle\" x=\"261\" y=\"-819.8\" font-family=\"Times,serif\" font-size=\"14.00\">&#45; Output key : paragraphs</text>\n",
       "<text text-anchor=\"middle\" x=\"261\" y=\"-804.8\" font-family=\"Times,serif\" font-size=\"14.00\">&#45; Input key : filename</text>\n",
       "<text text-anchor=\"middle\" x=\"261\" y=\"-789.8\" font-family=\"Times,serif\" font-size=\"14.00\">&#45; Function : utils.text.parsers.parse_document</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"1\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"410.5,-746 111.5,-746 111.5,-678 410.5,-678 410.5,-746\"/>\n",
       "<text text-anchor=\"middle\" x=\"261\" y=\"-730.8\" font-family=\"Times,serif\" font-size=\"14.00\">== Function ==</text>\n",
       "<text text-anchor=\"middle\" x=\"261\" y=\"-715.8\" font-family=\"Times,serif\" font-size=\"14.00\">&#45; Output key : pages</text>\n",
       "<text text-anchor=\"middle\" x=\"261\" y=\"-700.8\" font-family=\"Times,serif\" font-size=\"14.00\">&#45; Input key : paragraphs</text>\n",
       "<text text-anchor=\"middle\" x=\"261\" y=\"-685.8\" font-family=\"Times,serif\" font-size=\"14.00\">&#45; Function : __main__.group_paragraphs</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M261,-781.89C261,-773.78 261,-764.98 261,-756.47\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"264.5,-756.3 261,-746.3 257.5,-756.3 264.5,-756.3\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"2\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"261\" cy=\"-522.5\" rx=\"119.5\" ry=\"119.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"261\" y=\"-526.3\" font-family=\"Times,serif\" font-size=\"14.00\">== ContextValue ==</text>\n",
       "<text text-anchor=\"middle\" x=\"261\" y=\"-511.3\" font-family=\"Times,serif\" font-size=\"14.00\">&#45; Key : pages</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M261,-677.91C261,-670.19 261,-661.51 261,-652.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"264.5,-652.12 261,-642.12 257.5,-652.12 264.5,-652.12\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>5</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"147\" cy=\"-349\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"147\" y=\"-345.3\" font-family=\"Times,serif\" font-size=\"14.00\">item #1</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>2&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M195.02,-422.23C183.45,-404.83 172.38,-388.19 163.8,-375.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"166.46,-372.96 158.01,-366.57 160.63,-376.83 166.46,-372.96\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>6</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"261\" cy=\"-349\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"261\" y=\"-345.3\" font-family=\"Times,serif\" font-size=\"14.00\">item #2</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;6 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>2&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M261,-402.86C261,-393.57 261,-384.89 261,-377.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"264.5,-377.2 261,-367.2 257.5,-377.2 264.5,-377.2\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>7</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"378\" cy=\"-349\" rx=\"51.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"378\" y=\"-345.3\" font-family=\"Times,serif\" font-size=\"14.00\">item #...</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;7 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>2&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M328.04,-423.23C340.16,-405.47 351.77,-388.45 360.75,-375.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"363.77,-377.07 366.51,-366.84 357.99,-373.13 363.77,-377.07\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"4\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"347.5,-173 174.5,-173 174.5,-120 347.5,-120 347.5,-173\"/>\n",
       "<text text-anchor=\"middle\" x=\"261\" y=\"-157.8\" font-family=\"Times,serif\" font-size=\"14.00\">== TextExtractor ==</text>\n",
       "<text text-anchor=\"middle\" x=\"261\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\">&#45; Input key : llm_tags</text>\n",
       "<text text-anchor=\"middle\" x=\"261\" y=\"-127.8\" font-family=\"Times,serif\" font-size=\"14.00\">&#45; Pattern : &quot;(.*?)&quot;</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"8\" class=\"node\">\n",
       "<title>8</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"394,-84 128,-84 128,-16 394,-16 394,-84\"/>\n",
       "<text text-anchor=\"middle\" x=\"261\" y=\"-68.8\" font-family=\"Times,serif\" font-size=\"14.00\">== Function ==</text>\n",
       "<text text-anchor=\"middle\" x=\"261\" y=\"-53.8\" font-family=\"Times,serif\" font-size=\"14.00\">&#45; Output key : result</text>\n",
       "<text text-anchor=\"middle\" x=\"261\" y=\"-38.8\" font-family=\"Times,serif\" font-size=\"14.00\">&#45; Input key : tags_list</text>\n",
       "<text text-anchor=\"middle\" x=\"261\" y=\"-23.8\" font-family=\"Times,serif\" font-size=\"14.00\">&#45; Function : __main__.combine_tags</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;8 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>4&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M261,-119.68C261,-111.82 261,-102.96 261,-94.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"264.5,-94.25 261,-84.25 257.5,-94.25 264.5,-94.25\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"3\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"498,-292 24,-292 24,-209 498,-209 498,-292\"/>\n",
       "<text text-anchor=\"middle\" x=\"261\" y=\"-276.8\" font-family=\"Times,serif\" font-size=\"14.00\">== LLM ==</text>\n",
       "<text text-anchor=\"middle\" x=\"261\" y=\"-261.8\" font-family=\"Times,serif\" font-size=\"14.00\">&#45; Output key : llm_tags</text>\n",
       "<text text-anchor=\"middle\" x=\"261\" y=\"-246.8\" font-family=\"Times,serif\" font-size=\"14.00\">&#45; Input key : prompt</text>\n",
       "<text text-anchor=\"middle\" x=\"261\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\">&#45; Model &#160;: trtllm&#45;0.20.0_meta_llama_3.1_8b_instruct_int8_engine</text>\n",
       "<text text-anchor=\"middle\" x=\"261\" y=\"-216.8\" font-family=\"Times,serif\" font-size=\"14.00\">&#45; Method : answer</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M261,-208.89C261,-200.38 261,-191.46 261,-183.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"264.5,-183 261,-173 257.5,-183 264.5,-183\"/>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;3 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M165.57,-332.28C166.62,-331.39 167.7,-330.48 168.81,-329.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"171.17,-332.13 176.54,-323 166.64,-326.79 171.17,-332.13\"/>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;3 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>6&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M261,-330.75C261,-330.6 261,-330.44 261,-330.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"264.5,-333 261,-323 257.5,-333 264.5,-333\"/>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;3 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>7&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M358.94,-332.28C357.86,-331.39 356.75,-330.48 355.61,-329.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"357.63,-326.66 347.69,-323 353.17,-332.06 357.63,-326.66\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fca82400350>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
